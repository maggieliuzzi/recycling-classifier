# Image Classification Project

Convolutional neural network (CNN) for classifying images into various materials for accurate recycling.

The dataset used for training consists of:
```shell
- 2527 images among six categories, i.e. cardboard, glass, metal, paper, plastic, trash
- Web-scrapping (https://github.com/hardikvasa/google-images-download, uses ChromeDriver) (keywords: )
    Commands:
    pip install google_images_download
    brew tap homebrew/cask
    brew cask install chromedriver
    (which chromedriver)
    eg. googleimagesdownload -k 'lens flare daytime' -l 212 -cd /usr/local/bin/chromedriver
- OpenCV filters
```


## Installation

1. Install **Python 2.7** and **virtualenv** if you haven't - (should also work with Python 3.6, but needs further testing):

```shell
pip install virtualenv
```

2. Clone this repo to a directory of your choice:

```shell
git clone https://github.com/...
```

3. Enter the folder and create a new virtual environment:

```
cd material-classifier
virtualenv -p {path to your python 2.7 interpreter} venv
```

4. Install and add OpenCV to your virtual environment:

```shell
For macOS (based on https://www.youtube.com/watch?v=iluST-V757A):
brew update (or install)
brew tap brewsci/bio
brew install opencv3 --with-contrib
cd usr/local/Cellar/opencv (use your path)
cd {version you want to use}
cd lib/python2.7/site-packages (or the version of python you want to use)
pwd (and copy the location)
{path/to/cv2.{}.so} (should find it, even if permission is denied)
cd venv (find and cd into the virtual environment you created)
source venv/bin/activate (to activate your virtual environment; omit "source" if on Windows)
cd lib/python2.7/site-packages
ln -s {path/to/cv2.{}.so} {cv2.so} (saving as cv2.so is optional)
cd ../../../ (to root of virtual environment)
pip install numpy
python
>>> import cv2
```

5. Install the project's dependencies:

```shell
pip install -r requirements.txt
```

With that, you should be good to go!



Predicting:

* **detector.py** takes an image and a model as arguments and classifies the image as 'Cardboard', 'Glass', 'Metal', 'Paper', 'Plastic' and 'Trash'.
* **server.py** scripts start a server that receives HTTP POST request with a test image and outputs the estimated probabilities. 
Eg: http://0.0.0.0:4000/predict
"prediction": {
    "Cardboard": 0.9543766379356384,
    "Glass": 0.01101667433977127,
    etc
}
* **predict_functions.py** defines functions used to make predictions.


Preprocessing and training:

* **training.py** trains the network over a certain number of epochs and saves an .hdf5 model after every epoch to avoid retraining if it overfits.
* **preprocessing.py** separates data into training, validation and testing sets.


Testing:

* **testing.py** tests the quality of a model with the images in the test folder generated by running preprocessing.py.